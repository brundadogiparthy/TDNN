{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import all the required libraries\n",
                "import tensorflow as tf \n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "#from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
                "from sklearn.model_selection import train_test_split\n",
                "#from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
                "from tensorflow.keras import Model\n",
                "from tensorflow.keras import regularizers\n",
                "from tensorflow.keras.layers import *\n",
                "from tensorflow.keras.callbacks import *\n",
                "from tensorflow.keras.optimizers import *\n",
                "from tensorflow.keras.activations import *\n",
                "#from tensorflow.keras import backend as K"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Portion to load and prepare the dataset\n",
                "X = np.load('../data/data_used/np_data/DR_50s_400ms_cat_all_vowels.npy')\n",
                "# Normalize the dataset to values between 0 and 1.\n",
                "X = X / 184.5\n",
                "y_dom = np.load('../data/data_used/np_data/label_dom.npy')\n",
                "y_rec = np.load('../data/data_used/np_data/label_rec.npy')\n",
                "X_train, X_test, y_dom_train, y_dom_test, y_rec_train, y_rec_test = train_test_split(X, y_dom, y_rec, test_size=0.15, random_state=42)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Customised weighted loss function \n",
                "w_dom = 0.98\n",
                "w_rec = 0.02\n",
                "# def weighted_loss(y_true, y_pred):\n",
                "#     cce = tf.keras.losses.CategoricalCrossentropy()\n",
                "#     cce_dom = cce(tf.square(y_true[0] - y_pred[0])).numpy()\n",
                "#     cce_rec = cce(tf.square(y_true[1] - y_pred[1])).numpy()\n",
                "#     loss_fn = w_dom * cce_dom + w_rec * cce_rec\n",
                "#     return loss_fn\n",
                "\n",
                "# Due to heavy regularization, the output of the model might become very small. Vary the corr_factor to validate the identification scores pattern.\n",
                "# Keep the value as close to 1 as possible.\n",
                "corr_factor = 1.3125"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### I have also included the code from Peddinti et. al, 2015. Would strongly recommend experimenting with that model too."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model Architecture\n",
                "reg = 0.008\n",
                "def get_model(input_units = 40000, output_units = 5, pretrained_weights = None):\n",
                "    Inputs = Input(input_units,)\n",
                "    hidden = Dropout(0.4)(Inputs)\n",
                "    # Activation Function is Relu for the all the layers other than the last one. For last layer Activation function is Softmax.\n",
                "    hidden_1_1 = Lambda(lambda x: x[:,0:5000])(hidden)\n",
                "    hidden_1_2 = Lambda(lambda x: x[:,5000:10000])(hidden)\n",
                "    hidden_1_3 = Lambda(lambda x: x[:,10000:15000])(hidden)\n",
                "    hidden_1_4 = Lambda(lambda x: x[:,15000:20000])(hidden)\n",
                "    hidden_1_5 = Lambda(lambda x: x[:,20000:25000])(hidden)\n",
                "    hidden_1_6 = Lambda(lambda x: x[:,25000:30000])(hidden)\n",
                "    hidden_1_7 = Lambda(lambda x: x[:,30000:35000])(hidden)\n",
                "    hidden_1_8 = Lambda(lambda x: x[:,35000:40000])(hidden)\n",
                "    \n",
                "    hidden_1_1 = Dense(500, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_1_1)\n",
                "    hidden_1_2 = Dense(500, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_1_2)\n",
                "    hidden_1_3 = Dense(500, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_1_3)\n",
                "    hidden_1_4 = Dense(500, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_1_4)\n",
                "    hidden_1_5 = Dense(500, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_1_5)\n",
                "    hidden_1_6 = Dense(500, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_1_6)\n",
                "    hidden_1_7 = Dense(500, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_1_7)\n",
                "    hidden_1_8 = Dense(500, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_1_8)\n",
                "\n",
                "    hidden_2_1 = Concatenate()([hidden_1_1,hidden_1_2])\n",
                "    hidden_2_2 = Concatenate()([hidden_1_3,hidden_1_4])\n",
                "    hidden_2_3 = Concatenate()([hidden_1_5,hidden_1_6])\n",
                "    hidden_2_4 = Concatenate()([hidden_1_7,hidden_1_8])    \n",
                "\n",
                "    hidden_2_1 = Dense(200, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_2_1)\n",
                "    hidden_2_2 = Dense(200, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_2_2)\n",
                "    hidden_2_3 = Dense(200, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_2_3)\n",
                "    hidden_2_4 = Dense(200, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_2_4)\n",
                "\n",
                "    hidden_3_1 = Concatenate()([hidden_2_1,hidden_2_2])\n",
                "    hidden_3_2 = Concatenate()([hidden_2_3,hidden_2_4])\n",
                "\n",
                "    hidden_3_1 = Dense(80, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_3_1)\n",
                "    hidden_3_2 = Dense(80, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg))(hidden_3_2)\n",
                "\n",
                "    hidden_4_1 = Concatenate()([hidden_3_1,hidden_3_2])\n",
                "    \n",
                "    output_dominant = Dense(32, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg), bias_regularizer=regularizers.l2(reg))(hidden_4_1)\n",
                "    output_dominant = Dense(output_units, activation = None, kernel_regularizer=regularizers.l2(reg), bias_regularizer=regularizers.l2(reg), name='dense_dominant')(output_dominant)\n",
                "\n",
                "    output_recessive = Dense(32, activation = tf.nn.relu, kernel_regularizer=regularizers.l2(reg), bias_regularizer=regularizers.l2(reg))(hidden_4_1)\n",
                "    output_recessive = Dense(output_units, activation = None, kernel_regularizer=regularizers.l2(reg), bias_regularizer=regularizers.l2(reg), name='dense_recessive')(output_recessive)\n",
                "    \n",
                "    model = Model(inputs = Inputs, outputs = [output_dominant,output_recessive])\n",
                "    model.compile(optimizer = Adam(learning_rate = 0.001), loss = ['mse','mse'], loss_weights = [w_dom,w_rec], metrics = ['accuracy'])\n",
                "    # In case we have pretrained weights, we can use them to initialise the parameters.\n",
                "    if(pretrained_weights):\n",
                "    \tmodel.load_weights(pretrained_weights)\n",
                "    return model\n",
                "model = get_model()\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "log_dir = \"../logs/TDNN/model_30\" #Enter directory path for saving logs\n",
                "model_name = '../models/TDNN/model_30.hdf5' #Enter filename path for saving model\n",
                "\n",
                "#Callbacks\n",
                "tensorboard_callback = TensorBoard(log_dir=log_dir,update_freq='epoch')\n",
                "model_checkpoint = ModelCheckpoint(model_name, monitor='val_loss',verbose=1, save_best_only=True)\n",
                "lr_decay = ReduceLROnPlateau(monitor='val_loss', factor=0.7,patience=5, min_lr=0.0001)\n",
                "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
                "\n",
                "model = get_model()\n",
                "history = model.fit(x=X_train,y=[y_dom_train,y_rec_train],batch_size=100,epochs=20,validation_data=(X_test,[y_dom_test,y_rec_test]),callbacks=[tensorboard_callback, model_checkpoint, lr_decay, early_stop])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the accuracy and Loss\n",
                "#  \"Accuracy\"\n",
                "plt.plot(history.history['dense_dominant_accuracy'])\n",
                "plt.plot(history.history['val_dense_dominant_accuracy'])\n",
                "plt.plot(history.history['dense_recessive_accuracy'])\n",
                "plt.plot(history.history['val_dense_recessive_accuracy'])\n",
                "plt.title('model accuracy')\n",
                "plt.ylabel('accuracy')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['dense_dominant_accuracy', 'val_dense_dominant_accuracy','dense_recessive_accuracy','val_dense_recessive_accuracy'], loc='upper left')\n",
                "plt.show()\n",
                "\n",
                "# \"Vowel Loss\"\n",
                "plt.plot(history.history['dense_dominant_loss'])\n",
                "plt.plot(history.history['val_dense_dominant_loss'])\n",
                "plt.plot(history.history['dense_recessive_loss'])\n",
                "plt.plot(history.history['val_dense_recessive_loss'])\n",
                "plt.title('vowel loss')\n",
                "plt.ylabel('loss')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['dense_dominant_loss', 'val_dense_dominant_loss','dense_recessive_loss','dense_recessive_loss'], loc='upper left')\n",
                "plt.show()\n",
                "\n",
                "print(history.history['dense_dominant_loss'])\n",
                "print(history.history['val_dense_dominant_loss'])\n",
                "print(history.history['dense_recessive_loss'])\n",
                "print(history.history['val_dense_recessive_loss'])\n",
                "\n",
                "\n",
                "# \"Model Loss\"\n",
                "plt.plot(history.history['loss'])\n",
                "plt.plot(history.history['val_loss'])\n",
                "plt.title('model loss')\n",
                "plt.ylabel('loss')\n",
                "plt.xlabel('epoch')\n",
                "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
                "plt.show()\n",
                "\n",
                "print(history.history['loss'])\n",
                "print(history.history['val_loss'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Run the following code to obtain outputs from the model and to generate all the plots for identification scores."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Obtaining outputs for all semitones:\n",
                "outputs_dominant = []\n",
                "outputs_recessive = []\n",
                "model = tf.keras.models.load_model('../models/TDNN/model_30.hdf5')\n",
                "semi_list = [\"0s \",\"25s\",\"50s\",\"1s \",\"2s \",\"4s \"]\n",
                "for semi in semi_list:\n",
                "    X = np.load('../data/65_dBSPL/np_data/DR_{}_400ms_cat_all_vowels.npy'.format(semi)) \n",
                "    X = X / 184.5\n",
                "    output_dom,output_rec = model.predict(X)\n",
                "    outputs_dominant.append(output_dom)\n",
                "    outputs_recessive.append(output_rec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_semi = len(outputs_dominant)\n",
                "# The output_code array stores the dominant-recessive relations between the vowels in the pair. For more details refer to Chintanpalli et. al., 2016.\n",
                "output_code = np.array(\n",
                "    [[0,0],[1,0],[2,0],[3,0],[4,0],\n",
                "     [1,0],[1,1],[1,2],[3,1],[1,4],\n",
                "     [2,0],[1,2],[2,2],[2,3],[2,4],\n",
                "     [3,0],[3,1],[2,3],[3,3],[4,3],\n",
                "     [4,0],[1,4],[2,4],[4,3],[4,4]]\n",
                "     )  \n",
                "preds_dom = np.zeros([25,num_semi])\n",
                "preds_rec = np.zeros([25,num_semi])\n",
                "for j in range(num_semi):\n",
                "    output_dom = outputs_dominant[j]\n",
                "    output_rec = outputs_recessive[j]\n",
                "    for i in range(25):\n",
                "        pred_dom = output_dom[100*i:100*(i+1),output_code[i,0]]\n",
                "        pred_rec = output_rec[100*i:100*(i+1),output_code[i,1]]\n",
                "        mean_vec_dom = np.mean(pred_dom,axis=0)\n",
                "        mean_vec_rec= np.mean(pred_rec,axis=0)\n",
                "        pred_dom = pred_dom > mean_vec_dom/corr_factor\n",
                "        pred_rec = pred_rec > mean_vec_rec/corr_factor\n",
                "        preds_dom[i,j] = np.sum(pred_dom)\n",
                "        preds_rec[i,j] = np.sum(pred_rec)\n",
                "print(preds_dom.shape)\n",
                "print(preds_dom)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(preds_dom.shape)\n",
                "print(preds_rec.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Both Vowel Identification\n",
                "threshold = 80\n",
                "preds_bool = (preds_dom > threshold) * (preds_rec > threshold)\n",
                "points = preds_bool.sum(axis=0)*4\n",
                "print(points)\n",
                "\n",
                "plt.plot(np.array([0,1.5,3,6,12,26]),points[[0,1,2,3,4,5]],marker='s')\n",
                "plt.title('Both vowel identification')\n",
                "plt.xlabel('F0 difference(Hz)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.xlim([0,26])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Both Vowel Identification: Identical\n",
                "threshold = 80\n",
                "preds_bool = (preds_dom > threshold) * (preds_rec > threshold)\n",
                "points = preds_bool[[0,6,12,18,24]].sum(axis=0)*20\n",
                "print(points)\n",
                "\n",
                "plt.plot(np.array([0,1.5,3,6,12,26]),points[[0,1,2,3,4,5]],marker='s')\n",
                "plt.title('Both vowel identification (Identical)')\n",
                "plt.xlabel('F0 difference(Hz)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.xlim([0,26])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Both Vowel Identification: Different\n",
                "threshold = 80\n",
                "preds_bool = (preds_dom > threshold) * (preds_rec > threshold)\n",
                "points = preds_bool[[1,2,3,4,5,7,8,9,10,11,13,14,15,16,17,19,20,21,22,23]].sum(axis=0)*5\n",
                "print(points)\n",
                "\n",
                "plt.plot(np.array([0,1.5,3,6,12,26]),points[[0,1,2,3,4,5]],marker='s')\n",
                "plt.title('Both vowel identification (Different)')\n",
                "plt.xlabel('F0 difference(Hz)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.xlim([0,26])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Dominant Vowel Identification\n",
                "preds_bool = preds_dom > threshold\n",
                "points = preds_bool.sum(axis=0)*4\n",
                "print(points)\n",
                "\n",
                "plt.plot(np.array([0,1.5,3,6,12,26]),points[[0,1,2,3,4,5]],marker='s')\n",
                "plt.title('One vowel identification (Dominant)')\n",
                "plt.xlabel('F0 difference(Hz)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.xlim([0,26])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Recessive Vowel Identification\n",
                "preds_bool = preds_rec > threshold\n",
                "points = preds_bool.sum(axis=0)*4\n",
                "print(points)\n",
                "\n",
                "plt.plot(np.array([0,1.5,3,6,12,26]),points[[0,1,2,3,4,5]],marker='s')\n",
                "plt.title('One vowel identification (Recessive)')\n",
                "plt.xlabel('F0 difference(Hz)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.xlim([0,26])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Single Vowel Identification\n",
                "preds_bool = (preds_dom > threshold) + (preds_rec > threshold)\n",
                "points = preds_bool.sum(axis=0)*4\n",
                "print(points)\n",
                "\n",
                "plt.plot(np.array([0,1.5,3,6,12,26]),points[[0,1,2,3,4,5]],marker='s')\n",
                "plt.title('One vowel identification (Either)')\n",
                "plt.xlabel('F0 difference(Hz)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.xlim([0,26])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Single Vowel Identification: Identical\n",
                "preds_bool = (preds_dom > threshold) + (preds_rec > threshold)\n",
                "points = preds_bool[[0,6,12,18,24]].sum(axis=0)*20\n",
                "print(points)\n",
                "\n",
                "plt.plot(np.array([0,1.5,3,6,12,26]),points[[0,1,2,3,4,5]],marker='s')\n",
                "plt.title('One vowel identification (Either) (Identical)')\n",
                "plt.xlabel('F0 difference(Hz)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.xlim([0,26])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Single Vowel Identification: Different\n",
                "preds_bool = (preds_dom > threshold) + (preds_rec > threshold)\n",
                "points = preds_bool[[1,2,3,4,5,7,8,9,10,11,13,14,15,16,17,19,20,21,22,23]].sum(axis=0)*5\n",
                "print(points)\n",
                "\n",
                "plt.plot(np.array([0,1.5,3,6,12,26]),points[[0,1,2,3,4,5]],marker='s')\n",
                "plt.title('One vowel identification (Either) (Different)')\n",
                "plt.xlabel('F0 difference(Hz)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.xlim([0,26])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Use the subsequent code for levels study."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#LEVELS STUDY:\n",
                "#Obtaining outputs for all levels and semitones:\n",
                "\n",
                "model = tf.keras.models.load_model('../models/TDNN_levels/model_1.hdf5')\n",
                "output_code = np.array(\n",
                "    [[0,0],[1,0],[2,0],[3,0],[4,0],\n",
                "     [1,0],[1,1],[1,2],[3,1],[1,4],\n",
                "     [2,0],[1,2],[2,2],[2,3],[2,4],\n",
                "     [3,0],[3,1],[2,3],[3,3],[4,3],\n",
                "     [4,0],[1,4],[2,4],[4,3],[4,4]]\n",
                "     )\n",
                "semi_list = [\"0s \",\"4s \"]\n",
                "levels = ['25_dBSPL','35_dBSPL','50_dBSPL','65_dBSPL','75_dBSPL','85_dBSPL']\n",
                "threshold = 80\n",
                "num_levels = len(levels)\n",
                "print(num_levels)\n",
                "## In the same and diff F0, Column 0 is both vowel and Column 1 is single vowel\n",
                "same_f0 = np.zeros(shape=(num_levels,2))\n",
                "diff_f0 = np.zeros(shape=(num_levels,2))\n",
                "norm_values = [184.5,184.5,184.5,184.5,184.5,184.5]\n",
                "for num in range(num_levels):\n",
                "    outputs_dominant = []\n",
                "    outputs_recessive = []\n",
                "    for semi in semi_list:\n",
                "        X = np.load('../data/{}/np_data/DR_{}_400ms_cat_all_vowels.npy'.format(levels[num],semi)) \n",
                "        #X = scaler.transform(X)\n",
                "        X = X / norm_values[num]\n",
                "        output_dom,output_rec = model.predict(X)\n",
                "        outputs_dominant.append(output_dom)\n",
                "        outputs_recessive.append(output_rec)\n",
                "    num_semi = len(outputs_dominant)\n",
                "    preds_dom = np.zeros([25,num_semi])\n",
                "    preds_rec = np.zeros([25,num_semi])\n",
                "    for j in range(num_semi):\n",
                "        output_dom = outputs_dominant[j]\n",
                "        output_rec = outputs_recessive[j]\n",
                "        for i in range(25):\n",
                "            pred_dom = output_dom[100*i:100*(i+1),output_code[i,0]]\n",
                "            pred_rec = output_rec[100*i:100*(i+1),output_code[i,1]]\n",
                "            mean_vec_dom = np.mean(pred_dom,axis=0)\n",
                "            mean_vec_rec= np.mean(pred_rec,axis=0)\n",
                "            pred_dom = pred_dom > mean_vec_dom/corr_factor\n",
                "            pred_rec = pred_rec > mean_vec_rec/corr_factor\n",
                "            preds_dom[i,j] = np.sum(pred_dom)\n",
                "            preds_rec[i,j] = np.sum(pred_rec)\n",
                "    preds_bool_both = (preds_dom > threshold) * (preds_rec > threshold)\n",
                "    preds_bool_either = (preds_dom > threshold) + (preds_rec > threshold)\n",
                "    # Zero is same F0, 1 is different F0\n",
                "    points_both = preds_bool_both.sum(axis=0)*4\n",
                "    points_either = preds_bool_either.sum(axis=0)*4\n",
                "    same_f0[num,0] = points_both[0]\n",
                "    diff_f0[num,0] = points_both[1]\n",
                "    same_f0[num,1] = points_either[0]\n",
                "    diff_f0[num,1] = points_either[1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Level study: Both Vowel\n",
                "print(same_f0[:,0])\n",
                "print(diff_f0[:,0])\n",
                "plt.plot(np.array([25,35,50,65,75,85]),same_f0[:,0],marker='*')\n",
                "plt.plot(np.array([25,35,50,65,75,85]),diff_f0[:,0],marker='s')\n",
                "plt.title('Level study: Both Vowel')\n",
                "plt.xlabel('Vowel Level (dB SPL)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.legend(['Same F0','Different F0'],loc='best')\n",
                "plt.xlim([25,85])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### Level study: Either Vowel\n",
                "print(same_f0[:,1])\n",
                "print(diff_f0[:,1])\n",
                "plt.plot(np.array([25,35,50,65,75,85]),same_f0[:,1],marker='*')\n",
                "plt.plot(np.array([25,35,50,65,75,85]),diff_f0[:,1],marker='s')\n",
                "plt.title('Level study: Either Vowel')\n",
                "plt.xlabel('Vowel Level (dB SPL)')\n",
                "plt.ylabel('Percentage identification of both vowels')\n",
                "plt.legend(['Same F0','Different F0'],loc='best')\n",
                "plt.xlim([25,85])\n",
                "plt.ylim([0,110])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Trying out new metrics: \n",
                "\n",
                "# for j in range(len(outputs_dominant)):\n",
                "#     output_dom = outputs_dominant[j]\n",
                "#     output_dom = (output_dom.max(axis=1,keepdims=1)== output_dom).astype(int) \n",
                "#     auc_scores_dom = precision_score(y_dom,output_dom, average='macro')\n",
                "#     print(auc_scores_dom)\n",
                "\n",
                "\n",
                "# for j in range(len(outputs_recessive)):\n",
                "#     output_rec = outputs_recessive[j]\n",
                "#     output_rec = (output_rec.max(axis=1,keepdims=1) == output_rec).astype(int)\n",
                "#     auc_scores_rec = precision_score(y_rec,output_rec, average='macro')\n",
                "#     print(auc_scores_rec)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Saving Model Visualization:\n",
                "# from tensorflow.keras.utils import plot_model\n",
                "# from tensorflow.keras.models import load_model\n",
                "# model = load_model('../models/TDNN/model_4.hdf5')\n",
                "# plot_model(\n",
                "#     model,\n",
                "#     to_file=\"../models/TDNN/model_4_keras_util.png\",\n",
                "#     show_shapes=False,\n",
                "#     show_dtype=False,\n",
                "#     show_layer_names=False,\n",
                "#     rankdir=\"TB\",\n",
                "#     expand_nested=False,\n",
                "#     dpi=96,\n",
                "#     layer_range=None,\n",
                "# )"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "208fc564aa619409b95e5f415fd08d9526663020e9109b1f4632e8055bb70fe4"
        },
        "kernelspec": {
            "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
